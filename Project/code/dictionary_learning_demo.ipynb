{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import time\n",
    "import shelve\n",
    "import pickle\n",
    "import os.path as op\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn import linear_model, datasets\n",
    "\n",
    "from nt_toolbox.signal import load_image, imageplot, snr\n",
    "from nt_toolbox.general import clamp\n",
    "from utils import (random_dictionary, high_energy_random_dictionary,\n",
    "                  center, scale, reconstruction_error, plot_error, plot_dictionary)\n",
    "from dictionary_learning import (dictionary_update_ksvd, sparse_code_lasso, dictionary_update_omf,\n",
    "                                 sparse_code_fb, dictionary_update_fb)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "width = 5\n",
    "signal_size = width*width\n",
    "n_atoms = 2*signal_size\n",
    "n_samples = 20*n_atoms\n",
    "k = 4 # Desired sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "synthetic_data = True\n",
    "if synthetic_data:\n",
    "    Y, D0, X0 = datasets.make_sparse_coded_signal(n_samples, n_atoms, signal_size, k, random_state=0)\n",
    "else:\n",
    "    img_size = 256\n",
    "    filename = 'lena.bmp'\n",
    "    f0 = load_image(filename, img_size)\n",
    "\n",
    "    plt.figure(figsize = (6,6))\n",
    "    imageplot(f0, 'Image f_0')\n",
    "\n",
    "    D0 = high_energy_random_dictionary(f0, width, n_atoms)\n",
    "    Y = random_dictionary(f0, width, n_samples)\n",
    "    Y = center(Y) # TODO: Center because the dictionary is centered and no intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-SVD\n",
    "\n",
    "Aharon, Michal, Michael Elad, and Alfred Bruckstein. \"K-SVD: An Algorithm for Designing Overcomplete Dictionaries for Sparse Representation.\" IEEE Transactions on signal processing 54.11 (2006): 4311-4322."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_iter = 10\n",
    "E = np.zeros(2*n_iter)\n",
    "X = np.zeros((n_atoms, n_samples))\n",
    "D = np.random.random(D0.shape)\n",
    "for i in tqdm(range(n_iter)):\n",
    "    # Sparse coding\n",
    "    X = sparse_code_fb(Y, D, X, sparsity=k, n_iter=100)\n",
    "    E[2*i] = reconstruction_error(Y, D, X)\n",
    "\n",
    "    # Dictionary update\n",
    "    D, X = dictionary_update_ksvd(Y, D, X)\n",
    "    #D = dictionary_update_fb(Y, D, X, n_iter=50)\n",
    "    E[2*i+1] = reconstruction_error(Y, D, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_error(E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Backward\n",
    "\n",
    "Combettes, Patrick L., and Jean-Christophe Pesquet. \"Proximal splitting methods in signal processing.\" Fixed-point algorithms for inverse problems in science and engineering. Springer New York, 2011. 185-212.  \n",
    "\n",
    "Adapted from\n",
    "http://nbviewer.jupyter.org/github/gpeyre/numerical-tours/blob/master/matlab/sparsity_4_dictionary_learning.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_iter_learning = 5\n",
    "n_iter_dico = 50\n",
    "n_iter_coef = 100\n",
    "E = np.zeros(2*n_iter_learning)\n",
    "X = np.zeros((n_atoms, n_samples))\n",
    "D = D0\n",
    "for i in tqdm(range(n_iter_learning)):\n",
    "    # Sparse coding\n",
    "    X = sparse_code_fb(Y, D, X, sparsity=k, n_iter=n_iter_coef)\n",
    "    E[2*i] = reconstruction_error(Y, D, X)\n",
    "\n",
    "    # Dictionary update\n",
    "    D = dictionary_update_fb(Y, D, X, n_iter=n_iter_dico)\n",
    "    E[2*i+1] = reconstruction_error(Y, D, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_error(E)\n",
    "plot_dictionary(D0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online dictionary learning\n",
    "From \"Online Learning for Matrix Factorization and Sparse Coding\"  \n",
    "LARS-Lasso from LEAST ANGLE REGRESSION, Efron et al http://statweb.stanford.edu/~tibs/ftp/lars.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_iter = 5*n_samples\n",
    "test_interval = 1000\n",
    "lambd = 0.01 # L1 penalty coefficient for sparse coding\n",
    "lasso = linear_model.Lasso(lambd, fit_intercept=False) # TODO: use lars instead of lasso\n",
    "\n",
    "D = D0\n",
    "A = np.zeros((n_atoms,n_atoms))\n",
    "B = np.zeros((signal_size,n_atoms))\n",
    "\n",
    "sparsity = []\n",
    "E = []\n",
    "Y = random_dictionary(f0, width, 20*n_atoms)\n",
    "X = np.zeros((n_atoms, n_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in tqdm(range(n_iter)):\n",
    "    # Draw 1 random patch y and get its sparse coding\n",
    "    #y = random_dictionary(f0, width, n_atoms=1)\n",
    "    y = Y[:,np.random.randint(Y.shape[1])].reshape((signal_size,1))\n",
    "    x = lasso.fit(D, y).coef_.reshape((n_atoms,1))\n",
    "    A += np.dot(x,x.T)\n",
    "    B += np.dot(y,x.T)\n",
    "    D = dictionary_update_omf(D, A, B)\n",
    "    D = scale(D)\n",
    "    sparsity.append(np.mean(np.sum(x!=0, axis=0)))\n",
    "    \n",
    "    if i%test_interval == 0:\n",
    "        # Evaluation:\n",
    "        X = sparse_code_fb(Y, D, X, sparsity=4, n_iter=100)\n",
    "        E.append(reconstruction_error(Y, D, X))\n",
    "        #sparsity.append(np.mean(np.sum(X!=0, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(range(0, n_iter, test_interval), E)\n",
    "plt.title('Reconstruction error on the test set')\n",
    "plt.show()\n",
    "#plt.savefig('omf_2400000_iter.png')\n",
    "plt.figure(figsize=(8,12))\n",
    "plot_dictionary(D0)\n",
    "plt.title('D0')\n",
    "plt.show()\n",
    "plt.figure(figsize=(8,12))\n",
    "plot_dictionary(D)\n",
    "plt.title('D')\n",
    "plt.show()\n",
    "plt.plot(sparsity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = op.join('vars','omf_iter.out')\n",
    "with shelve.open(filename,'n') as shelf: # 'n' for new\n",
    "    for key in dir():\n",
    "        try:\n",
    "            shelf[key] = globals()[key]\n",
    "        except (TypeError, pickle.PicklingError, AttributeError):\n",
    "            #\n",
    "            # __builtins__, my_shelf, and imported modules can not be shelved.\n",
    "            #\n",
    "            print('ERROR shelving: {0}'.format(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x1 = np.array([[1,2,3]]).T\n",
    "x2 = np.array([[2,2,2]]).T\n",
    "X = np.array(np.hstack((x1,x2)))\n",
    "print(X.T)\n",
    "print(X)\n",
    "print(X.shape)\n",
    "print(np.dot(X, X.T))\n",
    "print(np.dot(x1,x1.T)+np.dot(x2,x2.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.dot(x1,x1.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
