{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code taken from  \n",
    "http://nbviewer.jupyter.org/github/gpeyre/numerical-tours/blob/master/python/inverse_5_inpainting_sparsity.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from nt_toolbox.signal import load_image, imageplot, snr\n",
    "from nt_toolbox.general import clamp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we consider inpainting of damaged observation without noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_size = 256\n",
    "#f0 = load_image('image.jpg', img_size)\n",
    "f0 = load_image('lena.bmp', img_size)\n",
    "\n",
    "plt.figure(figsize = (6,6))\n",
    "imageplot(f0, 'Image f_0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We construct a mask $\\Omega$ made of random pixel locations.  \n",
    "The damaging operator put to zeros the pixel locations $x$ for which $\\Omega(x)=1$.  \n",
    "The damaged observations reads $y = \\Phi f_0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "\n",
    "rho = .7 # percentage of removed pixels\n",
    "Omega = np.zeros([img_size, img_size])\n",
    "sel = random.permutation(img_size**2)\n",
    "np.ravel(Omega)[sel[np.arange(int(rho*img_size**2))]] = 1\n",
    "\n",
    "Phi = lambda f, Omega: f*(1-Omega)\n",
    "\n",
    "y = Phi(f0, Omega)\n",
    "\n",
    "plt.figure(figsize = (6,6))\n",
    "imageplot(y, 'Observations y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionary initialization inspired from  \n",
    "http://nbviewer.jupyter.org/github/gpeyre/numerical-tours/blob/master/matlab/sparsity_4_dictionary_learning.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = 10   # Width of the patches\n",
    "m = w*w  # Size of the signal to be sparse coded\n",
    "k = 2*m  # Number of atoms in the dictionary (overcomplete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a random patch in the damaged image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def random_patch(image, width, n_patches=1):\n",
    "    img_shape = image.shape\n",
    "    # Upper left corners of patches\n",
    "    rows = np.random.randint(0, img_shape[0]-width, n_patches)\n",
    "    cols = np.random.randint(0, img_shape[1]-width, n_patches)\n",
    "    \n",
    "    patches = np.zeros((n_patches, width, width))\n",
    "    for i in range(n_patches):\n",
    "        patches[i] = image[\n",
    "            rows[i]:rows[i]+width,\n",
    "            cols[i]:cols[i]+width\n",
    "        ]\n",
    "    return patches\n",
    "\n",
    "def plot_dictionary(D):\n",
    "    assert len(D.shape) == 3\n",
    "    assert D.shape[1] == D.shape[2]\n",
    "    n_patches = D.shape[0]\n",
    "    patch_size = D.shape[1]\n",
    "    n = int(np.ceil(np.sqrt(n_patches))) # Size of the square in number of patches\n",
    "\n",
    "    # Pad the images\n",
    "    pad_size = 1\n",
    "    missing_patches = n ** 2 - n_patches\n",
    "\n",
    "    padding = (((0, missing_patches),\n",
    "                (pad_size, pad_size), (pad_size, pad_size)))\n",
    "    D = np.pad(D, padding, mode='constant', constant_values=1)\n",
    "    padded_patch_size = patch_size + 2*pad_size\n",
    "    D = D.reshape(n,n,padded_patch_size,padded_patch_size)\n",
    "    D = D.transpose(0,2,1,3) # Needed for the reshape\n",
    "    big_image_size = n*padded_patch_size\n",
    "    D = D.reshape(big_image_size, big_image_size)\n",
    "    imageplot(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 2 Dictionary update\n",
    "From \"Online Learning for Matrix Factorization and Sparse Coding\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def update_dictionary(D, A, B):\n",
    "    '''\n",
    "    Update the dictionary column by column.\n",
    "    Denoting k the number of atoms in the dictionary and m the size of the signal, we have:\n",
    "    \n",
    "    Args:\n",
    "        D: dictionary of size (m,k)\n",
    "        A: Matrix of size (k,k)\n",
    "        B: Matrix of size (m,k)\n",
    "    Returns:\n",
    "        D: Updated dictionary of size (m,k)\n",
    "    '''\n",
    "    (m,k) = D.shape\n",
    "    assert A.shape == (k,k)\n",
    "    assert B.shape == (m,k)\n",
    "    \n",
    "    for j in range(k):        \n",
    "        uj = (B[:,j]-np.dot(D,A[:,j])) + D[:,j]\n",
    "        if A[j,j] != 0:\n",
    "            uj /= A[j,j]\n",
    "        else:\n",
    "            # TODO: What to do when A[j,j] is 0 ?\n",
    "            pass\n",
    "        D[:,j] = 1/max(np.linalg.norm(uj),1)*uj\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate(Y_test, D, model):\n",
    "    alpha = model.fit(D, Y_test).coef_\n",
    "    error = np.linalg.norm(Y_test - np.dot(D,alpha.T))\n",
    "    #score = model.score(D, Y_test)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 1 Online dictionary learning\n",
    "From \"Online Learning for Matrix Factorization and Sparse Coding\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Initialize variables\n",
    "T = 100 # Number of iterations\n",
    "lambd = 0.1 # L1 penalty coefficient for alpha\n",
    "# LARS-Lasso from LEAST ANGLE REGRESSION, Efron et al http://statweb.stanford.edu/~tibs/ftp/lars.pdf\n",
    "lasso = linear_model.Lasso(lambd, fit_intercept=False) # TODO: use lars instead of lasso\n",
    "\n",
    "D = random_patch(f0, w, n_patches=k) # Initialize dictionary with k random atoms\n",
    "D = D.reshape(k, m).T # Reshape each atom to column vector\n",
    "# TODO: normalize atom to unit norm as sparsity_4_dictionary_learning ?\n",
    "A = np.zeros((k,k))\n",
    "B = np.zeros((m,k))\n",
    "\n",
    "# Evaluation data initialization\n",
    "sparsity = []\n",
    "error = []\n",
    "n = 20*k # Number of patch to take for evaluation\n",
    "Y_test = random_patch(f0, w, n_patches=n)\n",
    "Y_test = Y_test.reshape((n,m)).T # Reshape each patch to column vector\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,12))\n",
    "plot_dictionary(D.T.reshape(k, w, w))\n",
    "\n",
    "start = time.time()\n",
    "for t in tqdm(range(T)):\n",
    "    x = random_patch(f0, w, n_patches=1).reshape((m,1)) # Draw 1 random patch as column vector\n",
    "    alpha = lasso.fit(D, x).coef_.reshape((k,1)) # Get the sparse coding # TODO: try with lasso.sparse_coef_\n",
    "    A += np.dot(alpha,alpha.T)\n",
    "    B += np.dot(x,alpha.T)\n",
    "    D = update_dictionary(D, A, B)\n",
    "    \n",
    "    if t%10 == 0:\n",
    "        # Evaluation:\n",
    "        error.append(evaluate(Y_test, D, lasso))\n",
    "        sparsity.append(np.sum(alpha!=0))#/alpha.shape[0]\n",
    "end = time.time()\n",
    "\n",
    "print('Time elapsed: %.3f s' % (end-start))\n",
    "plt.figure(figsize=(8,12))\n",
    "plot_dictionary(D.T.reshape(k, w, w))\n",
    "plt.figure(figsize=(8,12))\n",
    "plt.plot(error)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
