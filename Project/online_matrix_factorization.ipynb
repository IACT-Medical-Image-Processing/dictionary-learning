{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code taken from  \n",
    "http://nbviewer.jupyter.org/github/gpeyre/numerical-tours/blob/master/python/inverse_5_inpainting_sparsity.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from nt_toolbox.signal import load_image, imageplot, snr\n",
    "from nt_toolbox.general import clamp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary learning: numerical tour approach\n",
    "TODO: quote the matlab numerical tour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def random_dictionary(image, width, n_atoms):\n",
    "    '''\n",
    "    Takes an image as input and returns a dictionary\n",
    "    of shape (width*width, n_atoms)\n",
    "    '''\n",
    "    assert image.shape[0] == image.shape[1]\n",
    "    n0 = image.shape[0]\n",
    "    \n",
    "    # Random sampling of coordinates of the top left corner or the patches\n",
    "    x = (np.random.random((1,1,n_atoms))*(n0-width)).astype(int)\n",
    "    y = (np.random.random((1,1,n_atoms))*(n0-width)).astype(int)\n",
    "    \n",
    "    # Extract patches\n",
    "    [dY,dX] = np.meshgrid(range(width), range(width))\n",
    "    dX = np.tile(dX, (n_atoms,1,1)).transpose((1,2,0))\n",
    "    dY = np.tile(dY, (n_atoms,1,1)).transpose((1,2,0))\n",
    "    Xp = np.tile(x, (width,width,1)) + dX\n",
    "    Yp = dY + np.tile(y, (width,width,1))\n",
    "    D = image.flatten()[Yp+Xp*n0]\n",
    "    D = D.reshape((width*width,n_atoms)) # Reshape from (w,w,q) to (w*w,q)\n",
    "    return D\n",
    "\n",
    "def center(D):\n",
    "    '''\n",
    "    Takes a Dictionary of shape (signal_size, n_atoms) and\n",
    "    substract the signal-wise mean.\n",
    "    '''\n",
    "    assert len(D.shape) == 2\n",
    "    D -= D.mean(axis=0)\n",
    "    return D\n",
    "\n",
    "def scale(D):\n",
    "    ''' Scale the dictionary atoms to unit norm '''\n",
    "    assert len(D.shape) == 2\n",
    "    norm = np.tile(np.linalg.norm(D, axis=0), (D.shape[0],1))\n",
    "    D = np.divide(D, norm)\n",
    "    return D\n",
    "\n",
    "def high_energy_random_dictionary(image, width, n_atoms):\n",
    "    '''\n",
    "    Initialize a random dictionary with high energy centered and \n",
    "    normalized atoms  of size (width*width, n_atoms)\n",
    "    '''\n",
    "    m = 20*n_atoms\n",
    "    q = 3*m\n",
    "    D = random_dictionary(image, width, q)\n",
    "    D = center(D)\n",
    "    # Keep patches with highest energy\n",
    "    energies = np.sum(D**2, axis=0)\n",
    "    Indexes = np.argsort(energies)[::-1]\n",
    "    D = D[:,Indexes[:m]]\n",
    "    # Select a random subset of these patches\n",
    "    sel = np.random.permutation(range(m))[:n_atoms]\n",
    "    D = D[:,sel]\n",
    "    D = scale(D)\n",
    "    return D\n",
    "\n",
    "def plot_dictionary(D):\n",
    "    ''' Plot a dictionary of shape (width*width, n_atoms) '''\n",
    "    # Check that D.shape == (width*width, n_atoms)\n",
    "    assert len(D.shape) == 2\n",
    "    assert int(np.sqrt(D.shape[0]))**2 == D.shape[0]\n",
    "    (signal_size, n_atoms) = D.shape\n",
    "    width = int(np.sqrt(D.shape[0]))\n",
    "    D = D.reshape((width,width,n_atoms))\n",
    "    n = int(np.ceil(np.sqrt(n_atoms))) # Size of the plot square in number of atoms\n",
    "\n",
    "    # Pad the atoms\n",
    "    pad_size = 1\n",
    "    missing_atoms = n ** 2 - n_atoms\n",
    "\n",
    "    padding = (((pad_size, pad_size), (pad_size, pad_size),\n",
    "                (0, missing_atoms)))\n",
    "    D = np.pad(D, padding, mode='constant', constant_values=1)\n",
    "    padded_width = width + 2*pad_size\n",
    "    D = D.reshape(padded_width,padded_width,n,n)\n",
    "    D = D.transpose(2,0,3,1) # Needed for the reshape\n",
    "    big_image_size = n*padded_width\n",
    "    D = D.reshape(big_image_size, big_image_size)\n",
    "    imageplot(D)\n",
    "\n",
    "def ProjX(X,k):\n",
    "    ''' Sparsity projection, keeps the k largest coefficients '''\n",
    "    X = X * (abs(X) >= np.sort(abs(X), axis=0)[-k,:])\n",
    "    return X\n",
    "\n",
    "\n",
    "def ProjC(D):\n",
    "    ''' Dictionary projection, scales the atoms '''\n",
    "    D = scale(D)\n",
    "    return D\n",
    "\n",
    "def sparse_code_pgd(Y, D, X, sparsity=4, n_iter=100):\n",
    "    '''\n",
    "    Sparse code data Y using dictionary D using a forward backward iterative scheme.\n",
    "    This is a non-smooth and non-convex minimization, that can be shown to be NP-hard.\n",
    "    A heuristic to solve this method is to compute a stationary point of the energy\n",
    "    using the Foward-Backward iterative scheme (projected gradient descent).\n",
    "    '''\n",
    "    gamma = 1/np.linalg.norm(np.dot(D,D.T)) # TODO: Improve gamma ? (compare with nt)\n",
    "    for i in range(n_iter):\n",
    "        R = np.dot(D, X) - Y\n",
    "        X = ProjX(X - gamma * np.dot(D.T, R), sparsity)\n",
    "    return X\n",
    "\n",
    "def sparse_code_lasso(Y, D, model):\n",
    "    ''' Sparse code data Y using dictionary D using lasso linear regression '''\n",
    "    X = lasso.fit(D, Y).coef_.T\n",
    "    return X\n",
    "\n",
    "def dictionary_update_pgd(Y, D, X, n_iter=50):\n",
    "    tau = 1/np.linalg.norm(np.dot(X, X.T)) # TODO: Improve tau ? (compare with nt)\n",
    "    for i in range(n_iter):\n",
    "        R = np.dot(D, X) - Y\n",
    "        D = ProjC(D - tau * np.dot(R, X.T))\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_size = 256\n",
    "filename = 'image.jpg'\n",
    "filename = 'barb_crop.png'\n",
    "filename = 'lena.bmp'\n",
    "f0 = load_image(filename, img_size)\n",
    "\n",
    "plt.figure(figsize = (6,6))\n",
    "imageplot(f0, 'Image f_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "width = 10\n",
    "signal_size = width*width\n",
    "n_atoms = 2*signal_size\n",
    "n_test = 20*n_atoms\n",
    "k = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D0 = high_energy_random_dictionary(f0, width, n_atoms)\n",
    "Y_test = random_dictionary(f0, width, n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_iter_learning = 6\n",
    "n_iter_dico = 25\n",
    "n_iter_coef = 50\n",
    "E = np.zeros(2*n_iter_learning)\n",
    "X = np.zeros((n_atoms, n_test))\n",
    "D = D0\n",
    "for i in tqdm(range(n_iter_learning)):\n",
    "    # --- coefficient update ----\n",
    "    X = sparse_code_pgd(Y_test, D, X, sparsity=k, n_iter=n_iter_coef)\n",
    "    E[2*i] = np.linalg.norm(Y_test - np.dot(D, X))**2\n",
    "    # --- dictionary update ----\n",
    "    D = dictionary_update_pgd(Y_test, D, X, n_iter=n_iter_dico)\n",
    "    E[2*i+1] = np.linalg.norm(Y_test - np.dot(D, X))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove first points (burn in)\n",
    "start = 4\n",
    "assert start%2==0\n",
    "E_plot = E[start:]\n",
    "\n",
    "plt.plot(range(E_plot.shape[0]), E_plot)\n",
    "index_coef = list(range(0, E_plot.shape[0], 2))\n",
    "index_dico = list(range(1, E_plot.shape[0], 2))\n",
    "plt.plot(index_coef, E_plot[index_coef], '*', label='After coefficient update')\n",
    "plt.plot(index_dico, E_plot[index_dico], 'o', label='After dictionary update')\n",
    "plt.legend(numpoints=1)\n",
    "plt.title('$J(x)$')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,12))\n",
    "plot_dictionary(D0)\n",
    "plt.title('D0')\n",
    "plt.show()\n",
    "plt.figure(figsize=(8,12))\n",
    "plot_dictionary(D)\n",
    "plt.title('D')\n",
    "plt.show()\n",
    "\n",
    "min(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_test = 1000\n",
    "Y_test = random_dictionary(f0, width, n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X0 = np.zeros((n_atoms, n_test))\n",
    "tic = time.time()\n",
    "for j in range(n_iter_coef):\n",
    "    R = np.dot(D, X0) - Y_test\n",
    "    X0 = ProjX(X0 - gamma * np.dot(D.T, R), k)\n",
    "print(time.time()-tic)\n",
    "print(np.sum(X0!=0, axis=0))\n",
    "np.linalg.norm(Y_test - np.dot(D, X0))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.linalg.norm(Y_test - np.dot(D, X0))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lasso = linear_model.Lasso(0.01, fit_intercept=False)\n",
    "tic = time.time()\n",
    "X1 = lasso.fit(D, Y_test).coef_.T\n",
    "print(time.time()-tic)\n",
    "print(np.sum(X1!=0, axis=0))\n",
    "np.linalg.norm(Y_test - np.dot(D, X1))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(np.sum(X1!=0, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X1[:,0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We construct a mask $\\Omega$ made of random pixel locations.  \n",
    "The damaging operator put to zeros the pixel locations $x$ for which $\\Omega(x)=1$.  \n",
    "The damaged observations reads $y = \\Phi f_0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def damage_image(image):\n",
    "    rho = .7 # percentage of removed pixels\n",
    "    Omega = np.zeros([img_size, img_size])\n",
    "    sel = np.random.permutation(img_size**2)\n",
    "    np.ravel(Omega)[sel[np.arange(int(rho*img_size**2))]] = 1\n",
    "\n",
    "    Phi = lambda f, Omega: f*(1-Omega)\n",
    "\n",
    "    damaged_image = Phi(image, Omega)\n",
    "    return damaged_image\n",
    "\n",
    "y = damage_image(f0)\n",
    "plt.figure(figsize = (6,6))\n",
    "imageplot(y, 'Observations y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 2 Dictionary update\n",
    "From \"Online Learning for Matrix Factorization and Sparse Coding\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def update_dictionary(D, A, B):\n",
    "    '''\n",
    "    Update the dictionary column by column.\n",
    "    Denoting k the number of atoms in the dictionary and m the size of the signal, we have:\n",
    "    \n",
    "    Args:\n",
    "        D: dictionary of size (m,k)\n",
    "        A: Matrix of size (k,k)\n",
    "        B: Matrix of size (m,k)\n",
    "    Returns:\n",
    "        D: Updated dictionary of size (m,k)\n",
    "    '''\n",
    "    (m,k) = D.shape\n",
    "    assert A.shape == (k,k)\n",
    "    assert B.shape == (m,k)\n",
    "    \n",
    "    for j in range(k):        \n",
    "        uj = (B[:,j]-np.dot(D,A[:,j])) + D[:,j]\n",
    "        if A[j,j] != 0:\n",
    "            uj /= A[j,j]\n",
    "        else:\n",
    "            # TODO: What to do when A[j,j] is 0 ?\n",
    "            pass\n",
    "        D[:,j] = 1/max(np.linalg.norm(uj),1)*uj\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate(Y_test, D, model):\n",
    "    X = model.fit(D, Y_test).coef_\n",
    "    error = np.linalg.norm(Y_test - np.dot(D,X.T))\n",
    "    #score = model.score(D, Y_test)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 1 Online dictionary learning\n",
    "From \"Online Learning for Matrix Factorization and Sparse Coding\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Initialize variables\n",
    "T = 100 # Number of iterations\n",
    "lambd = 0.1 # L1 penalty coefficient for alpha\n",
    "# LARS-Lasso from LEAST ANGLE REGRESSION, Efron et al http://statweb.stanford.edu/~tibs/ftp/lars.pdf\n",
    "lasso = linear_model.Lasso(lambd, fit_intercept=False) # TODO: use lars instead of lasso\n",
    "\n",
    "D0 = high_energy_random_dictionary(f0, width, n_atoms) # Initialize dictionary with k random atoms\n",
    "D = D0\n",
    "# TODO: normalize atom to unit norm as sparsity_4_dictionary_learning ?\n",
    "A = np.zeros((n_atoms,n_atoms))\n",
    "B = np.zeros((signal_size,n_atoms))\n",
    "\n",
    "# Evaluation data initialization\n",
    "sparsity = []\n",
    "error = []\n",
    "Y_test = random_dictionary(f0, width, 20*n_atoms)\n",
    "\n",
    "for t in tqdm(range(T)):\n",
    "    y = random_dictionary(f0, width, n_atoms=1) # Draw 1 random patch as column vector\n",
    "    x = lasso.fit(D, y).coef_.reshape((n_atoms,1)) # Get the sparse coding # TODO: try with lasso.sparse_coef_\n",
    "    A += np.dot(x,x.T)\n",
    "    B += np.dot(y,x.T)\n",
    "    D = update_dictionary(D, A, B)\n",
    "    \n",
    "    if t%10 == 0:\n",
    "        # Evaluation:\n",
    "        error.append(evaluate(Y_test, D, lasso))\n",
    "        sparsity.append(np.sum(x!=0))#/alpha.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(error)\n",
    "plt.show()\n",
    "plt.figure(figsize=(8,12))\n",
    "plot_dictionary(D0)\n",
    "plt.title('D0')\n",
    "plt.show()\n",
    "plt.figure(figsize=(8,12))\n",
    "plot_dictionary(D)\n",
    "plt.title('D')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array([[1,2],[2,3],[-1,3]]).T\n",
    "1/np.linalg.norm(np.dot(X, X.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sqrt(np.sum(np.dot(X, X.T)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array([[1,2,3], [4,3,2], [-1,5,3],[-3,-8,2]]).T"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
