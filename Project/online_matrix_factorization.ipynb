{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code taken from  \n",
    "http://nbviewer.jupyter.org/github/gpeyre/numerical-tours/blob/master/python/inverse_5_inpainting_sparsity.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn import linear_model\n",
    "\n",
    "from nt_toolbox.signal import load_image, imageplot, snr\n",
    "from nt_toolbox.general import clamp\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary learning\n",
    "TODO: quote the matlab numerical tour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def damage_image(image):\n",
    "    rho = .7 # percentage of removed pixels\n",
    "    Omega = np.zeros([img_size, img_size])\n",
    "    sel = np.random.permutation(img_size**2)\n",
    "    np.ravel(Omega)[sel[np.arange(int(rho*img_size**2))]] = 1\n",
    "\n",
    "    Phi = lambda f, Omega: f*(1-Omega)\n",
    "\n",
    "    damaged_image = Phi(image, Omega)\n",
    "    return damaged_image\n",
    "\n",
    "def random_dictionary(image, width, n_atoms):\n",
    "    '''\n",
    "    Takes an image as input and returns a dictionary\n",
    "    of shape (width*width, n_atoms)\n",
    "    '''\n",
    "    assert image.shape[0] == image.shape[1]\n",
    "    n0 = image.shape[0]\n",
    "    \n",
    "    # Random sampling of coordinates of the top left corner or the patches\n",
    "    x = (np.random.random((1,1,n_atoms))*(n0-width)).astype(int)\n",
    "    y = (np.random.random((1,1,n_atoms))*(n0-width)).astype(int)\n",
    "    \n",
    "    # Extract patches\n",
    "    [dY,dX] = np.meshgrid(range(width), range(width))\n",
    "    dX = np.tile(dX, (n_atoms,1,1)).transpose((1,2,0))\n",
    "    dY = np.tile(dY, (n_atoms,1,1)).transpose((1,2,0))\n",
    "    Xp = np.tile(x, (width,width,1)) + dX\n",
    "    Yp = dY + np.tile(y, (width,width,1))\n",
    "    D = image.flatten()[Yp+Xp*n0]\n",
    "    D = D.reshape((width*width,n_atoms)) # Reshape from (w,w,q) to (w*w,q)\n",
    "    return D\n",
    "\n",
    "def center(D):\n",
    "    '''\n",
    "    Takes a Dictionary of shape (signal_size, n_atoms) and\n",
    "    substract the signal-wise mean.\n",
    "    '''\n",
    "    assert len(D.shape) == 2\n",
    "    D -= D.mean(axis=0)\n",
    "    return D\n",
    "\n",
    "def scale(D):\n",
    "    ''' Scale the dictionary atoms to unit norm '''\n",
    "    assert len(D.shape) == 2\n",
    "    norm = np.tile(np.linalg.norm(D, axis=0), (D.shape[0],1))\n",
    "    D = np.divide(D, norm)\n",
    "    return D\n",
    "\n",
    "def high_energy_random_dictionary(image, width, n_atoms):\n",
    "    '''\n",
    "    Initialize a random dictionary with high energy centered and \n",
    "    normalized atoms  of size (width*width, n_atoms)\n",
    "    '''\n",
    "    m = 20*n_atoms\n",
    "    q = 3*m\n",
    "    D = random_dictionary(image, width, q)\n",
    "    D = center(D)\n",
    "    # Keep patches with highest energy\n",
    "    energies = np.sum(D**2, axis=0)\n",
    "    Indexes = np.argsort(energies)[::-1]\n",
    "    D = D[:,Indexes[:m]]\n",
    "    # Select a random subset of these patches\n",
    "    sel = np.random.permutation(range(m))[:n_atoms]\n",
    "    D = D[:,sel]\n",
    "    D = scale(D)\n",
    "    return D\n",
    "\n",
    "def plot_dictionary(D):\n",
    "    ''' Plot a dictionary of shape (width*width, n_atoms) '''\n",
    "    # Check that D.shape == (width*width, n_atoms)\n",
    "    assert len(D.shape) == 2\n",
    "    assert int(np.sqrt(D.shape[0]))**2 == D.shape[0]\n",
    "    (signal_size, n_atoms) = D.shape\n",
    "    width = int(np.sqrt(D.shape[0]))\n",
    "    D = D.reshape((width,width,n_atoms))\n",
    "    n = int(np.ceil(np.sqrt(n_atoms))) # Size of the plot square in number of atoms\n",
    "\n",
    "    # Pad the atoms\n",
    "    pad_size = 1\n",
    "    missing_atoms = n ** 2 - n_atoms\n",
    "\n",
    "    padding = (((pad_size, pad_size), (pad_size, pad_size),\n",
    "                (0, missing_atoms)))\n",
    "    D = np.pad(D, padding, mode='constant', constant_values=1)\n",
    "    padded_width = width + 2*pad_size\n",
    "    D = D.reshape(padded_width,padded_width,n,n)\n",
    "    D = D.transpose(2,0,3,1) # Needed for the reshape\n",
    "    big_image_size = n*padded_width\n",
    "    D = D.reshape(big_image_size, big_image_size)\n",
    "    imageplot(D)\n",
    "\n",
    "def ProjX(X,k):\n",
    "    ''' Sparsity projection, keeps the k largest coefficients '''\n",
    "    X = X * (abs(X) >= np.sort(abs(X), axis=0)[-k,:])\n",
    "    return X\n",
    "\n",
    "\n",
    "def ProjC(D):\n",
    "    ''' Dictionary projection, scales the atoms '''\n",
    "    D = scale(D)\n",
    "    return D\n",
    "\n",
    "def sparse_code_pgd(Y, D, X, sparsity=4, n_iter=100):\n",
    "    '''\n",
    "    Sparse code data Y using dictionary D using a forward backward iterative scheme.\n",
    "    This is a non-smooth and non-convex minimization, that can be shown to be NP-hard.\n",
    "    A heuristic to solve this method is to compute a stationary point of the energy\n",
    "    using the Foward-Backward iterative scheme (projected gradient descent).\n",
    "    '''\n",
    "    gamma = 1/np.linalg.norm(np.dot(D,D.T)) # TODO: Improve gamma ? (compare with nt)\n",
    "    for i in range(n_iter):\n",
    "        R = np.dot(D, X) - Y\n",
    "        X = ProjX(X - gamma * np.dot(D.T, R), sparsity)\n",
    "    return X\n",
    "\n",
    "def sparse_code_lasso(Y, D, model):\n",
    "    ''' Sparse code data Y using dictionary D using lasso linear regression '''\n",
    "    X = lasso.fit(D, Y).coef_.T\n",
    "    return X\n",
    "\n",
    "def dictionary_update_pgd(Y, D, X, n_iter=50):\n",
    "    tau = 1/np.linalg.norm(np.dot(X, X.T)) # TODO: Improve tau ? (compare with nt)\n",
    "    for i in range(n_iter):\n",
    "        R = np.dot(D, X) - Y\n",
    "        D = ProjC(D - tau * np.dot(R, X.T))\n",
    "    return D\n",
    "\n",
    "def dictionary_update_omf(D, A, B):\n",
    "    '''\n",
    "    Algorithm 2 from \"Online Learning for Matrix Factorization and Sparse Coding\n",
    "    Update the dictionary column by column.\n",
    "    Denoting k the number of atoms in the dictionary and m the size of the signal, we have:\n",
    "    \n",
    "    Args:\n",
    "        D: dictionary of size (m,k)\n",
    "        A: Matrix of size (k,k)\n",
    "        B: Matrix of size (m,k)\n",
    "    Returns:\n",
    "        D: Updated dictionary of size (m,k)\n",
    "    '''\n",
    "    (m,k) = D.shape\n",
    "    assert A.shape == (k,k)\n",
    "    assert B.shape == (m,k)\n",
    "    \n",
    "    for j in range(k):        \n",
    "        uj = (B[:,j]-np.dot(D,A[:,j])) + D[:,j]\n",
    "        if A[j,j] != 0:\n",
    "            uj /= A[j,j]\n",
    "        else:\n",
    "            # TODO: What to do when A[j,j] is 0 ?\n",
    "            pass\n",
    "        D[:,j] = 1/max(np.linalg.norm(uj),1)*uj\n",
    "    return D\n",
    "\n",
    "def reconstruction_error(Y, D, X):\n",
    "    error = np.linalg.norm(Y_test - np.dot(D, X))**2\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_size = 256\n",
    "filename = 'image.jpg'\n",
    "filename = 'barb_crop.png'\n",
    "filename = 'lena.bmp'\n",
    "f0 = load_image(filename, img_size)\n",
    "\n",
    "plt.figure(figsize = (6,6))\n",
    "imageplot(f0, 'Image f_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "width = 10\n",
    "signal_size = width*width\n",
    "n_atoms = 2*signal_size\n",
    "n_test = 20*n_atoms\n",
    "k = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D0 = high_energy_random_dictionary(f0, width, n_atoms)\n",
    "Y_test = random_dictionary(f0, width, n_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical tour approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_iter_learning = 10\n",
    "n_iter_dico = 50\n",
    "n_iter_coef = 100\n",
    "E = np.zeros(2*n_iter_learning)\n",
    "X = np.zeros((n_atoms, n_test))\n",
    "D = D0\n",
    "for i in tqdm(range(n_iter_learning)):\n",
    "    # --- coefficient update ----\n",
    "    X = sparse_code_pgd(Y_test, D, X, sparsity=k, n_iter=n_iter_coef)\n",
    "    E[2*i] = reconstruction_error(Y_test, D, X)\n",
    "    # --- dictionary update ----\n",
    "    D = dictionary_update_pgd(Y_test, D, X, n_iter=n_iter_dico)\n",
    "    E[2*i+1] = reconstruction_error(Y_test, D, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove first points (burn in)\n",
    "start = 4\n",
    "assert start%2==0\n",
    "E_plot = E[start:]\n",
    "\n",
    "plt.plot(range(E_plot.shape[0]), E_plot)\n",
    "index_coef = list(range(0, E_plot.shape[0], 2))\n",
    "index_dico = list(range(1, E_plot.shape[0], 2))\n",
    "plt.plot(index_coef, E_plot[index_coef], '*', label='After coefficient update')\n",
    "plt.plot(index_dico, E_plot[index_dico], 'o', label='After dictionary update')\n",
    "plt.legend(numpoints=1)\n",
    "plt.title('Reconstruction error')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,12))\n",
    "plot_dictionary(D0)\n",
    "plt.title('D0')\n",
    "plt.show()\n",
    "plt.figure(figsize=(8,12))\n",
    "plot_dictionary(D)\n",
    "plt.title('D')\n",
    "plt.show()\n",
    "\n",
    "min(E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online dictionary learning\n",
    "From \"Online Learning for Matrix Factorization and Sparse Coding\"  \n",
    "LARS-Lasso from LEAST ANGLE REGRESSION, Efron et al http://statweb.stanford.edu/~tibs/ftp/lars.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_iter = 10*n_test\n",
    "lambd = 0.1 # L1 penalty coefficient for sparse coding\n",
    "lasso = linear_model.Lasso(lambd, fit_intercept=False) # TODO: use lars instead of lasso\n",
    "\n",
    "D = D0\n",
    "A = np.zeros((n_atoms,n_atoms))\n",
    "B = np.zeros((signal_size,n_atoms))\n",
    "\n",
    "sparsity = []\n",
    "E = []\n",
    "Y_test = random_dictionary(f0, width, 20*n_atoms)\n",
    "X = np.zeros((n_atoms, n_test))\n",
    "for i in tqdm(range(n_iter)):\n",
    "    # Draw 1 random patch y and get its sparse coding\n",
    "    #y = random_dictionary(f0, width, n_atoms=1)\n",
    "    y = Y_test[:,np.random.randint(Y_test.shape[1])].reshape((signal_size,1))\n",
    "    x = lasso.fit(D, y).coef_.reshape((n_atoms,1))\n",
    "    A += np.dot(x,x.T)\n",
    "    B += np.dot(y,x.T)\n",
    "    D = dictionary_update_omf(D, A, B)\n",
    "    \n",
    "    if i%n_test == 0:\n",
    "        # Evaluation:\n",
    "        X = sparse_code_pgd(Y_test, D, X, sparsity=4, n_iter=100)\n",
    "        E.append(reconstruction_error(Y_test, D, X))\n",
    "        sparsity.append(np.sum(x!=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(E)\n",
    "plt.show()\n",
    "plt.figure(figsize=(8,12))\n",
    "plot_dictionary(D0)\n",
    "plt.title('D0')\n",
    "plt.show()\n",
    "plt.figure(figsize=(8,12))\n",
    "plot_dictionary(D)\n",
    "plt.title('D')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
