{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code taken from  \n",
    "http://nbviewer.jupyter.org/github/gpeyre/numerical-tours/blob/master/python/inverse_5_inpainting_sparsity.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from nt_toolbox.signal import load_image, imageplot, snr\n",
    "from nt_toolbox.general import clamp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we consider inpainting of damaged observation without noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_size = 256\n",
    "#f0 = load_image('image.jpg', img_size)\n",
    "f0 = load_image('lena.bmp', img_size)\n",
    "\n",
    "plt.figure(figsize = (6,6))\n",
    "imageplot(f0, 'Image f_0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We construct a mask $\\Omega$ made of random pixel locations.  \n",
    "The damaging operator put to zeros the pixel locations $x$ for which $\\Omega(x)=1$.  \n",
    "The damaged observations reads $y = \\Phi f_0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "\n",
    "rho = .7 # percentage of removed pixels\n",
    "Omega = np.zeros([img_size, img_size])\n",
    "sel = random.permutation(img_size**2)\n",
    "np.ravel(Omega)[sel[np.arange(int(rho*img_size**2))]] = 1\n",
    "\n",
    "Phi = lambda f, Omega: f*(1-Omega)\n",
    "\n",
    "y = Phi(f0, Omega)\n",
    "\n",
    "plt.figure(figsize = (6,6))\n",
    "imageplot(y, 'Observations y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionary initialization inspired from  \n",
    "http://nbviewer.jupyter.org/github/gpeyre/numerical-tours/blob/master/matlab/sparsity_4_dictionary_learning.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = 10   # Width of the patches\n",
    "m = w*w  # Size of the signal to be sparse coded\n",
    "k = 2*m  # Number of atoms in the dictionary (overcomplete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a random patch in the damaged image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def random_patch(image, width, n_patches=1):\n",
    "    img_shape = image.shape\n",
    "    # Upper left corners of patches\n",
    "    rows = np.random.randint(0, img_shape[0]-width, n_patches)\n",
    "    cols = np.random.randint(0, img_shape[1]-width, n_patches)\n",
    "    \n",
    "    patches = np.zeros((width*width, n_patches))\n",
    "    for i in range(n_patches):\n",
    "        patch = image[\n",
    "            rows[i]:rows[i]+width,\n",
    "            cols[i]:cols[i]+width\n",
    "        ]\n",
    "        patches[:,i] = patch.flatten()\n",
    "    \n",
    "    return patches\n",
    "\n",
    "def plot_dictionary(D):\n",
    "    '''\n",
    "    Plot a dictionary of shape (width*width, n_atoms)\n",
    "    '''\n",
    "    # Check that D.shape == (width*width, n_atoms)\n",
    "    assert len(D.shape) == 2\n",
    "    assert int(np.sqrt(D.shape[0]))**2 == D.shape[0]\n",
    "    (signal_size, n_atoms) = D.shape\n",
    "    width = int(np.sqrt(D.shape[0]))\n",
    "    D = D.reshape((width,width,n_atoms))\n",
    "    n = int(np.ceil(np.sqrt(n_atoms))) # Size of the plot square in number of atoms\n",
    "\n",
    "    # Pad the atoms\n",
    "    pad_size = 1\n",
    "    missing_atoms = n ** 2 - n_atoms\n",
    "\n",
    "    padding = (((pad_size, pad_size), (pad_size, pad_size),\n",
    "                (0, missing_atoms)))\n",
    "    D = np.pad(D, padding, mode='constant', constant_values=1)\n",
    "    padded_width = width + 2*pad_size\n",
    "    D = D.reshape(padded_width,padded_width,n,n)\n",
    "    D = D.transpose(2,0,3,1) # Needed for the reshape\n",
    "    big_image_size = n*padded_width\n",
    "    D = D.reshape(big_image_size, big_image_size)\n",
    "    imageplot(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 2 Dictionary update\n",
    "From \"Online Learning for Matrix Factorization and Sparse Coding\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def update_dictionary(D, A, B):\n",
    "    '''\n",
    "    Update the dictionary column by column.\n",
    "    Denoting k the number of atoms in the dictionary and m the size of the signal, we have:\n",
    "    \n",
    "    Args:\n",
    "        D: dictionary of size (m,k)\n",
    "        A: Matrix of size (k,k)\n",
    "        B: Matrix of size (m,k)\n",
    "    Returns:\n",
    "        D: Updated dictionary of size (m,k)\n",
    "    '''\n",
    "    (m,k) = D.shape\n",
    "    assert A.shape == (k,k)\n",
    "    assert B.shape == (m,k)\n",
    "    \n",
    "    for j in range(k):        \n",
    "        uj = (B[:,j]-np.dot(D,A[:,j])) + D[:,j]\n",
    "        if A[j,j] != 0:\n",
    "            uj /= A[j,j]\n",
    "        else:\n",
    "            # TODO: What to do when A[j,j] is 0 ?\n",
    "            pass\n",
    "        D[:,j] = 1/max(np.linalg.norm(uj),1)*uj\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate(Y_test, D, model):\n",
    "    alpha = model.fit(D, Y_test).coef_\n",
    "    error = np.linalg.norm(Y_test - np.dot(D,alpha.T))\n",
    "    #score = model.score(D, Y_test)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 1 Online dictionary learning\n",
    "From \"Online Learning for Matrix Factorization and Sparse Coding\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Initialize variables\n",
    "T = 100 # Number of iterations\n",
    "lambd = 0.1 # L1 penalty coefficient for alpha\n",
    "# LARS-Lasso from LEAST ANGLE REGRESSION, Efron et al http://statweb.stanford.edu/~tibs/ftp/lars.pdf\n",
    "lasso = linear_model.Lasso(lambd, fit_intercept=False) # TODO: use lars instead of lasso\n",
    "\n",
    "D = high_energy_random_dictionary(f0, w, n_atoms=k) # Initialize dictionary with k random atoms\n",
    "# TODO: normalize atom to unit norm as sparsity_4_dictionary_learning ?\n",
    "A = np.zeros((k,k))\n",
    "B = np.zeros((m,k))\n",
    "\n",
    "# Evaluation data initialization\n",
    "sparsity = []\n",
    "error = []\n",
    "n = 20*k # Number of patch to take for evaluation\n",
    "Y_test = random_dictionary(f0, w, n_atoms=n)\n",
    "\n",
    "plt.figure(figsize=(8,12))\n",
    "plot_dictionary(D)\n",
    "\n",
    "start = time.time()\n",
    "for t in tqdm(range(T)):\n",
    "    x = random_dictionary(f0, w, n_atoms=1) # Draw 1 random patch as column vector\n",
    "    alpha = lasso.fit(D, x).coef_.reshape((k,1)) # Get the sparse coding # TODO: try with lasso.sparse_coef_\n",
    "    A += np.dot(alpha,alpha.T)\n",
    "    B += np.dot(x,alpha.T)\n",
    "    D = update_dictionary(D, A, B)\n",
    "    \n",
    "    if t%10 == 0:\n",
    "        # Evaluation:\n",
    "        error.append(evaluate(Y_test, D, lasso))\n",
    "        sparsity.append(np.sum(alpha!=0))#/alpha.shape[0]\n",
    "end = time.time()\n",
    "\n",
    "print('Time elapsed: %.3f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,12))\n",
    "plot_dictionary(D)\n",
    "plt.figure(figsize=(8,12))\n",
    "plt.plot(error)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_dictionary(image, width, n_atoms):\n",
    "    '''\n",
    "    Takes an image as input and returns a dictionary\n",
    "    of shape (width*width, n_atoms)\n",
    "    '''\n",
    "    assert image.shape[0] == image.shape[1]\n",
    "    n0 = image.shape[0]\n",
    "    \n",
    "    # Random sampling of coordinates of the top left corner or the patches\n",
    "    x = (np.random.random((1,1,n_atoms))*(n0-width)).astype(int)\n",
    "    y = (np.random.random((1,1,n_atoms))*(n0-width)).astype(int)\n",
    "    \n",
    "    # Extract patches\n",
    "    [dY,dX] = np.meshgrid(range(width), range(width))\n",
    "    dX = np.tile(dX, (n_atoms,1,1)).transpose((1,2,0))\n",
    "    dY = np.tile(dY, (n_atoms,1,1)).transpose((1,2,0))\n",
    "    Xp = np.tile(x, (width,width,1)) + dX\n",
    "    Yp = dY + np.tile(y, (width,width,1))\n",
    "    D = image.flatten()[Yp+Xp*n0]\n",
    "    D = D.reshape((width*width,n_atoms)) # Reshape from (w,w,q) to (w*w,q)\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def center(D):\n",
    "    '''\n",
    "    Takes a Dictionary of shape (signal_size, n_atoms) and\n",
    "    substract the signal-wise mean.\n",
    "    '''\n",
    "    assert len(D.shape) == 2\n",
    "    D -= D.mean(axis=0)\n",
    "    return D\n",
    "\n",
    "def scale(D):\n",
    "    '''\n",
    "    Scale the dictionary atoms to unit norm\n",
    "    '''\n",
    "    assert len(D.shape) == 2\n",
    "    norm = np.tile(np.linalg.norm(D, axis=0), (D.shape[0],1))\n",
    "    D = np.divide(D, norm)\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def high_energy_random_dictionary(image, width, n_atoms):\n",
    "    '''\n",
    "    Initialize a random dictionary with high energy centered and \n",
    "    normalized atoms  of size (width*width, n_atoms)\n",
    "    '''\n",
    "    m = 20*n_atoms\n",
    "    q = 3*m\n",
    "    D = random_dictionary(image, width, q)\n",
    "    D = center(D)\n",
    "    # Keep patches with highest energy\n",
    "    energies = np.sum(D**2, axis=0)\n",
    "    Indexes = np.argsort(energies)[::-1]\n",
    "    D = D[:,Indexes[:m]]\n",
    "    # Select a random subset of these patches\n",
    "    sel = np.random.permutation(range(m))[:n_atoms]\n",
    "    D = D[:,sel]\n",
    "    D = scale(D)\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_size = 256\n",
    "f0 = load_image('barb_crop.png', img_size)\n",
    "\n",
    "#plt.figure(figsize = (6,6))\n",
    "imageplot(f0, 'Image f_0')\n",
    "n0 = f0.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "width = 10\n",
    "signal_size = width*width\n",
    "n_atoms = 2*signal_size\n",
    "n_test = 20*n_atoms\n",
    "k = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D0 = high_energy_random_dictionary(f0, width, n_atoms)\n",
    "Y = random_dictionary(f0, width, n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sparsity projection, keeps the k largest coefficients\n",
    "ProjX = lambda X,k: X * (abs(X) >= np.sort(abs(X))[-k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "projC = scale\n",
    "\n",
    "n_iter_learning = 1\n",
    "n_iter_dico = 50\n",
    "n_iter_coef = 100\n",
    "E = np.zeros(2*n_iter_learning)\n",
    "X = np.zeros((n_atoms, n_test))\n",
    "D = D0\n",
    "pbar = tqdm(total=n_iter_learning*(n_iter_dico+n_iter_coef))\n",
    "for i in range(n_iter_learning):\n",
    "    # --- coefficient update ----\n",
    "    gamma = 1.6/np.linalg.norm(D)**2\n",
    "    for j in range(n_iter_coef):\n",
    "        R = np.dot(D, X) - Y\n",
    "        X = ProjX(X - gamma * np.dot(D.T, R), k)\n",
    "        pbar.update(1)\n",
    "    E[2*i] = np.linalg.norm(Y - np.dot(D, X))**2\n",
    "    # --- dictionary update ----\n",
    "    tau = 1/np.linalg.norm(np.dot(X, X.T)) # TODO: check if it is the same value\n",
    "    for j in range(n_iter_dico):\n",
    "        R = np.dot(D, X) - Y\n",
    "        D = ProjC(D - tau * np.dot(R, X.T))\n",
    "        pbar.update(1)\n",
    "    E[2*i+1] = np.linalg.norm(Y - np.dot(D, X))**2\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(range(2*n_iter_learning), E)\n",
    "index_coef = list(range(0, 2*n_iter_learning, 2))\n",
    "index_dico = list(range(1, 2*n_iter_learning, 2))\n",
    "plt.plot(index_coef, E[index_coef], '*', label='After coefficient update')\n",
    "plt.plot(index_dico, E[index_dico], 'o', label='After dictionary update')\n",
    "plt.legend(numpoints=1)\n",
    "plt.title('$J(x)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
